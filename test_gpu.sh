#!/bin/bash

echo "üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ FRDA"
echo "======================================="

# –ü—Ä–æ–≤–µ—Ä—è–µ–º nvidia-smi –Ω–∞ —Ö–æ—Å—Ç–µ
echo "1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –Ω–∞ —Ö–æ—Å—Ç–µ..."
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv,noheader,nounits
    echo "‚úÖ GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–∞ —Ö–æ—Å—Ç–µ"
else
    echo "‚ùå nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ NVIDIA –¥—Ä–∞–π–≤–µ—Ä—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã."
    exit 1
fi

echo ""

# –ü—Ä–æ–≤–µ—Ä—è–µ–º NVIDIA Container Toolkit
echo "2Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ NVIDIA Container Toolkit..."
if docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi > /dev/null 2>&1; then
    echo "‚úÖ NVIDIA Container Toolkit —Ä–∞–±–æ—Ç–∞–µ—Ç"
else
    echo "‚ùå NVIDIA Container Toolkit –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ:"
    echo "   curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -"
    echo "   distribution=\$(. /etc/os-release;echo \$ID\$VERSION_ID)"
    echo "   curl -s -L https://nvidia.github.io/nvidia-docker/\$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list"
    echo "   sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit"
    echo "   sudo systemctl restart docker"
    exit 1
fi

echo ""

# –ó–∞–ø—É—Å–∫–∞–µ–º GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
echo "3Ô∏è‚É£ –ó–∞–ø—É—Å–∫ GPU –≤–æ—Ä–∫–µ—Ä–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è..."
echo "   (–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)"

# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–æ–ª—å–∫–æ GPU –≤–æ—Ä–∫–µ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
docker-compose -f docker-compose.gpu.yml up -d postgres redis minio minio-setup

# –ñ–¥–µ–º –ø–æ–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è
echo "   –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã..."
sleep 10

# –ó–∞–ø—É—Å–∫–∞–µ–º GPU –≤–æ—Ä–∫–µ—Ä
docker-compose -f docker-compose.gpu.yml up -d gpu-worker

echo ""
echo "4Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch –≤ GPU –≤–æ—Ä–∫–µ—Ä–µ..."
sleep 20  # –î–∞–µ–º –≤—Ä–µ–º—è –≤–æ—Ä–∫–µ—Ä—É –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è

if docker exec data-generation-gpu-worker python -c "import torch; print('‚úÖ PyTorch –¥–æ—Å—Ç—É–ø–µ–Ω:', torch.__version__); print('‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞:', torch.cuda.is_available()); print('‚úÖ GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤:', torch.cuda.device_count()); print('‚úÖ GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A')" 2>/dev/null; then
    echo "‚úÖ GPU –≤–æ—Ä–∫–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ!"
else
    echo "‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å PyTorch –≤ GPU –≤–æ—Ä–∫–µ—Ä–µ"
    echo "   –õ–æ–≥–∏ –≤–æ—Ä–∫–µ—Ä–∞:"
    docker-compose -f docker-compose.gpu.yml logs gpu-worker | tail -20
fi

echo ""

# –ü—Ä–æ–≤–µ—Ä—è–µ–º inference worker
echo "5Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ inference worker..."
docker-compose -f docker-compose.gpu.yml up -d inference-worker
sleep 10

if docker exec inference-worker-gpu python -c "import torch; print('‚úÖ Inference PyTorch:', torch.__version__); print('‚úÖ Inference CUDA:', torch.cuda.is_available())" 2>/dev/null; then
    echo "‚úÖ Inference worker –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ!"
else
    echo "‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å inference worker"
    echo "   –õ–æ–≥–∏ inference worker:"
    docker-compose -f docker-compose.gpu.yml logs inference-worker | tail -10
fi

echo ""
echo "üéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
echo ""
echo "üìä –î–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ GPU –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:"
echo "   watch -n 1 nvidia-smi"
echo ""
echo "üìù –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ª–æ–≥–æ–≤:"
echo "   docker-compose -f docker-compose.gpu.yml logs -f gpu-worker"
echo "   docker-compose -f docker-compose.gpu.yml logs -f inference-worker"
echo ""
echo "üõë –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏:"
echo "   docker-compose -f docker-compose.gpu.yml down" 