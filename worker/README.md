# Worker Module

## Назначение (Purpose)

Модуль `worker` является ключевым компонентом платформы **FRD.ai** и отвечает за выполнение всех "тяжелых" асинхронных задач. Он спроектирован для обработки ресурсоемких операций, таких как генерация данных, валидация и дообучение моделей, не блокируя при этом основной API.

## Архитектура (Architecture)

Воркер построен на базе **Celery** с использованием **Redis** в качестве брокера сообщений. Такая архитектура позволяет эффективно распределять и масштабировать задачи.

Ключевой особенностью является разделение задач на две специализированные очереди:

-   `cpu_queue`: Для задач, интенсивно использующих CPU (например, генерация и валидация данных).
-   `gpu_queue`: Для задач, требующих GPU-ресурсов (например, дообучение LoRA).

Такое разделение позволяет оптимально использовать вычислительные ресурсы и избежать конфликтов.

## Основные компоненты и задачи (Core Components & Tasks)

### 1. `celery_app.py`

Этот файл содержит определение и конфигурацию экземпляра Celery-приложения. Он настраивает брокер сообщений (Redis) и определяет очереди задач.

### 2. `tasks.py`

Центральный файл, в котором определены все асинхронные задачи. Каждая задача привязана к соответствующей очереди.

-   **`generate_dataset_task` (`cpu_queue`)**
    -   **Что делает:** Генерирует новый, расширенный датасет на основе "seed" данных, используя "модель-учителя" (self-instruct).
    -   **Вход:** UUID "seed" датасета.
    -   **Выход:** Сгенерированный датасет, сохраненный в MinIO.

-   **`validate_dataset_task` (`cpu_queue`)**
    -   **Что делает:** Проводит полную программную валидацию сгенерированного датасета по различным метрикам (например, `BLEU`, `ROUGE-L`, валидность JSON).
    -   **Вход:** UUID сгенерированного датасета.
    -   **Выход:** Обновленный статус датасета (`READY_FOR_FINE_TUNING` или `DELETED`).

-   **`fine_tune_lora_task` (`gpu_queue`)**
    -   **Что делает:** Запускает процесс дообучения LoRA-адаптера для базовой языковой модели. Включает в себя байесовскую оптимизацию для подбора наилучших гиперпараметров (`rank`, `lora_alpha`, `learning_rate`).
    -   **Вход:** UUID датасета, готового к дообучению, название базовой модели.
    -   **Выход:** Лучший LoRA-адаптер, сохраненный в MinIO (в bucket `lora-adapters`).

### 3. Модули задач

-   **`generate/`**: Содержит логику для генерации данных.
-   **`validation/`**: Реализует метрики и логику для валидации датасетов.
-   **`lora/`**: Содержит всю логику для дообучения LoRA, включая:
    -   `lora_tuning.py`: Функции для загрузки модели, подготовки датасета и запуска одного цикла обучения.
    -   `bayesian_optimizer.py`: Класс для проведения байесовской оптимизации гиперпараметров.
    -   `lora_tuning_config.py`: Конфигурация для процесса дообучения.

## Конфигурация (Configuration)

Настройки воркера управляются через переменные окружения. Ключевые параметры включают:

-   `REDIS_HOST`, `REDIS_PORT`: Параметры подключения к Redis.
-   `MINIO_ENDPOINT`, `MINIO_ACCESS_KEY`, `MINIO_SECRET_KEY`: Доступ к MinIO.
-   `LORA_MODEL_NAME`, `LORA_N_TRIALS`: Параметры для дообучения LoRA.

Полный список переменных можно найти в файле `docker-compose.yml`.

## Запуск (Running the Worker)

Воркеры запускаются как Docker-контейнеры. Для запуска используйте `docker-compose`:

```bash
# Запустить все сервисы, включая воркеры
docker-compose up -d

# Запустить только CPU-воркер
docker-compose up -d cpu-worker

# Запустить только GPU-воркер
docker-compose up -d gpu-worker
```

Для просмотра логов конкретного воркера:

```bash
docker-compose logs -f cpu-worker
docker-compose logs -f gpu-worker
```
